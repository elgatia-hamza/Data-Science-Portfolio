{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hawaiian-convenience",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-kuwait",
   "metadata": {},
   "source": [
    "<img src='CNN.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-maintenance",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "taken-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential    # for initializing the neural network (graphe)\n",
    "from keras.layers import Convolution2D # for making the convolutional neural layer firs layer\n",
    "from keras.layers import MaxPooling2D  \n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-trade",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considerable-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the cnn\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-forty",
   "metadata": {},
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complete-stack",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64,64,3), activation='relu')) #Convolution2D(nb_filter=, nb_rows= , nb_column=,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-ethernet",
   "metadata": {},
   "source": [
    "### Step 2 - Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ordinary-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.add(MaxPooling2D( pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-holiday",
   "metadata": {},
   "source": [
    "### Step 3 - Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32, 3,3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-drill",
   "metadata": {},
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hybrid-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-secondary",
   "metadata": {},
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confirmed-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 128, activation ='relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-senegal",
   "metadata": {},
   "source": [
    "### Compile the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stock-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-geology",
   "metadata": {},
   "source": [
    "## Part1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-ready",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-miller",
   "metadata": {},
   "source": [
    "### Generating image for the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,      # crop the image  \n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-trigger",
   "metadata": {},
   "source": [
    "### Generating images for the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handed-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-distribution",
   "metadata": {},
   "source": [
    "### Creating the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "choice-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-affiliation",
   "metadata": {},
   "source": [
    "### Creating the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "banned-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-oakland",
   "metadata": {},
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-digit",
   "metadata": {},
   "source": [
    "### Training the CNN on the Training set and evaluatin it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "experimental-facing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=25, validation_data=<keras.pre..., validation_steps=2000, steps_per_epoch=250)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 227s 910ms/step - loss: 0.5612 - accuracy: 0.7163 - val_loss: 0.5898 - val_accuracy: 0.7483\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 161s 643ms/step - loss: 0.5241 - accuracy: 0.7420 - val_loss: 0.5904 - val_accuracy: 0.7444\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 158s 630ms/step - loss: 0.5018 - accuracy: 0.7538 - val_loss: 0.5402 - val_accuracy: 0.7611\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 155s 619ms/step - loss: 0.4826 - accuracy: 0.7695 - val_loss: 0.3867 - val_accuracy: 0.7594\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 154s 617ms/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.5233 - val_accuracy: 0.7676\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 158s 633ms/step - loss: 0.4628 - accuracy: 0.7775 - val_loss: 0.4841 - val_accuracy: 0.7812\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 155s 620ms/step - loss: 0.4429 - accuracy: 0.7914 - val_loss: 0.4214 - val_accuracy: 0.7884\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 156s 623ms/step - loss: 0.4278 - accuracy: 0.7972 - val_loss: 0.4861 - val_accuracy: 0.7516\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 154s 616ms/step - loss: 0.4263 - accuracy: 0.8025 - val_loss: 0.4231 - val_accuracy: 0.7722\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 153s 614ms/step - loss: 0.4016 - accuracy: 0.8152 - val_loss: 0.4494 - val_accuracy: 0.7917\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 154s 616ms/step - loss: 0.3948 - accuracy: 0.8149 - val_loss: 0.3486 - val_accuracy: 0.7912\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 156s 625ms/step - loss: 0.3880 - accuracy: 0.8211 - val_loss: 0.2616 - val_accuracy: 0.7918\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 153s 614ms/step - loss: 0.3721 - accuracy: 0.8300 - val_loss: 0.6531 - val_accuracy: 0.8026\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 154s 618ms/step - loss: 0.3753 - accuracy: 0.8275 - val_loss: 0.3399 - val_accuracy: 0.7651\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 154s 616ms/step - loss: 0.3569 - accuracy: 0.8378 - val_loss: 0.5858 - val_accuracy: 0.8040\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 156s 622ms/step - loss: 0.3462 - accuracy: 0.8410 - val_loss: 0.2296 - val_accuracy: 0.8011\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 154s 616ms/step - loss: 0.3342 - accuracy: 0.8526 - val_loss: 0.2559 - val_accuracy: 0.8052\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 154s 617ms/step - loss: 0.3255 - accuracy: 0.8569 - val_loss: 0.2051 - val_accuracy: 0.8018\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 155s 619ms/step - loss: 0.3229 - accuracy: 0.8608 - val_loss: 0.3551 - val_accuracy: 0.8032\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 159s 635ms/step - loss: 0.3049 - accuracy: 0.8680 - val_loss: 0.3003 - val_accuracy: 0.8021\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 156s 623ms/step - loss: 0.3020 - accuracy: 0.8686 - val_loss: 0.5871 - val_accuracy: 0.8063\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 154s 615ms/step - loss: 0.3006 - accuracy: 0.8698 - val_loss: 0.5343 - val_accuracy: 0.8158\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 155s 620ms/step - loss: 0.2768 - accuracy: 0.8799 - val_loss: 0.3029 - val_accuracy: 0.8049\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 155s 619ms/step - loss: 0.2764 - accuracy: 0.8825 - val_loss: 0.5186 - val_accuracy: 0.8119\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 153s 611ms/step - loss: 0.2686 - accuracy: 0.8846 - val_loss: 0.7057 - val_accuracy: 0.8004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bf2b19d348>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, \n",
    "                        samples_per_epoch = 8000,\n",
    "                        epochs = 25,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps = 2000)                        \n",
    "#                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-bargain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-singles",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
